import os
import torch
import torch.nn.functional as F
from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast

model_path = os.path.join('data', 'lid_model')

print(f"–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –∏–∑ {model_path}...")
model = DistilBertForSequenceClassification.from_pretrained(model_path)
tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)

# –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
model.eval()

# –ï—Å–ª–∏ –µ—Å—Ç—å GPU, –∫–∏–¥–∞–µ–º —Ç—É–¥–∞ (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏), –µ—Å–ª–∏ –Ω–µ—Ç - –Ω–∞ CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)


# 2. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏
def predict_language(text, temperature=2):
    """
    temperature: 
        1.0 - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
        >1.0 - —Å–º—è–≥—á–µ–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ø–æ–∫–∞–∂–µ—Ç 70/30 –≤–º–µ—Å—Ç–æ 99/0)
    """
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –¥–µ–≤–∞–π—Å
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        outputs = model(**inputs)
    
    # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏—Ç—ã
    logits = outputs.logits
    
    # --- –¢–†–Æ–ö –° –¢–ï–ú–ü–ï–†–ê–¢–£–†–û–ô ---
    # –î–µ–ª–∏–º –ª–æ–≥–∏—Ç—ã –Ω–∞ —á–∏—Å–ª–æ > 1. –≠—Ç–æ "—Å–ø–ª—é—â–∏–≤–∞–µ—Ç" —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π.
    # –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É KK –∏ RU —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –º–µ–Ω—å—à–µ.
    scaled_logits = logits / temperature
    
    # Softmax —É–∂–µ –æ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–æ–≥–∏—Ç–æ–≤
    probs = F.softmax(scaled_logits, dim=-1) # [prob_KK, prob_RU]
    
    # –î–æ—Å—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    prob_kk = probs[0][0].item() * 100
    prob_ru = probs[0][1].item() * 100
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª—è (–æ–Ω –Ω–µ –∏–∑–º–µ–Ω–∏—Ç—Å—è –æ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã, —Ç–æ–ª—å–∫–æ % –∏–∑–º–µ–Ω–∏—Ç—Å—è)
    predicted_label = "KK" if prob_kk > prob_ru else "RU"
    confidence = max(prob_kk, prob_ru)
    
    return {
        "text": text,
        "label": predicted_label,
        "confidence": f"{confidence:.2f}%",
        "scores": {"KK": f"{prob_kk:.2f}%", "RU": f"{prob_ru:.2f}%"}
    }


# 3. –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö!
test_phrases = [
    # "–°”ô–ª–µ–º, “õ–∞–ª–∞–π—Å—ã“£? –ë“Ø–≥—ñ–Ω –∫–∏–Ω–æ“ì–∞ –±–∞—Ä–∞–π—ã“õ—à—ã.",  # –ß–∏—Å—Ç—ã–π KZ
    # "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞? –ü–æ–π–¥–µ–º —Å–µ–≥–æ–¥–Ω—è –≤ –∫–∏–Ω–æ.",   # –ß–∏—Å—Ç—ã–π RU
    # "–°”ô–ª–µ–º –±—Ä–∞—Ç, –∫–∞–ª–∞–π—Å—ã–Ω? –°–∫–∏–Ω—å –¥–æ–º–∞—à–∫—É –ø–ª–∏–∑.", # –¢–æ—Ç —Å–∞–º—ã–π –®–∞–ª–∞-–ö–∞–∑–∞—Ö—Å–∫–∏–π
    # "–ö–æ—Ä–æ—á–µ, –º–µ–Ω –±“Ø–≥—ñ–Ω –Ω–µ –ø—Ä–∏–¥—É, –∞—É—ã—Ä—ã–ø “õ–∞–ª–¥—ã–º.", # –ú–∏–∫—Å —Å —Ä—É—Å—Å–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
    # "–ö–∞–∑ –∫–µ–ª–µ–º, –∫—É—Ç.",                            # –ö–æ—Ä–æ—Ç–∫–∏–π —Å–ª–µ–Ω–≥
    # "–ú–∞—à–∏–Ω–∞–Ω—ã –ø–∞—Ä–∫–æ–≤–∫–∞–≥–∞ –∫–æ–π–¥—ã–º.",                 # –†—É—Å–∏–∑–º—ã –≤ KZ
    # '–†–µ–∫–ª–∞–º–∞ –Ω–µ —Å—Ç–æ–π—Ç —Ö–æ—Ç—è –±—ã 24 —Å–∞“ì–∞—Ç —Ç“±—Ä–º–∞–¥—ã, Zell–æ“ì–∞ —Å–∞–ª—ã–ø –∂—ñ–±–µ—Ä–µ–º –ø–∞—Ä–∞“õ—à–∞“£—ã–∑–¥—ã',
    # '–í—ã –º–æ–ª–æ–¥–µ—Ü! –•–æ—Ç—å —Å—Ç–∞—Ä–∞–µ—Ç–µ—Å—å –∫–∞–∑–∞–∫—à–∞ —Å–æ–π–ª–µ—É–≥–µ! ‚ù§Ô∏èüëèüî•–•–æ—Ç—è –± –∑–∞ –¥–µ–Ω—å–≥–∏',
    # '—Å–∏–∑–≥–µ —É–ª–∫–µ–Ω —Ä–∞—Ö–º–µ—Ç . –û—Å—ã —Å–ø–æ—Ä—Ç–∏–≤–∫–∞–Ω—ã –∏ —Ñ—É–¥–±—Ä–ª–∫–∞ –∞–ª“ì–∞–Ω–º—ã–Ω  –ê—Å—Ç–∞–Ω–∞ –∫–∞–ª–∞—Å—ã–Ω–∞ –¥–∞–∂–µ –û—Ç–µ –∫—É—à—Ç–∏ —Å–∞–ø–∞—Å—ã  –æ–≥–æ–Ω—å–≥–æ–π —Ä–∞—Ö–º–µ—Ç . –ö–∞—Ç—Ç—ã —É–Ω–∞–¥—ã  –ë—Ä–∞—Ç–∏—à–∫–∞–º–∞ –ø–æ–¥–∞—Ä–æ–∫–∫–∞ –∞–ª–≥–∞–Ω–º—ã–Ω —Ñ–æ—Ç–æ–≥–∞ —Ç—É—Å–∏—Ä–∏–ø –∂–∏–±–µ—Ä–µ–º–∏–∑',
    # '–º–∞–≥–∞–Ω –¥–≤–∞–¥—Ü–∞—Ç—å –ø–µ—Ä–≤–æ–≥–æ –Ω–µ —É–¥–æ–±–Ω–æ, –¥–∞–≤–∞–π—Ç–µ –¥–≤–∞–¥—Ü–∞—Ç—å –≤—Ç–æ—Ä–æ–≥–æ –±–∞—Ä–∞–º—ã–∑',
    # "–º–µ–Ω –µ—Ä—Ç–µ“£ —É–Ω–∏–∫—Ç–∞ –±–∞—Ä–∞–º—ã–Ω –∂”ô–Ω–µ —Ñ—Ä–∞–Ω—Ü—É–∑–ª—ã–∫ —à–æ–∫–æ–ª–∞–¥–ø–µ–Ω –±—É–ª–æ—á–∫–∞–Ω—ã –∞–ª–∞–º—ã–Ω"
    # "–ú–µ–Ω “õ–∞–∑–∞“õ—à–∞ —á–∏—Å—Ç–æ —Å”©–π–ª–µ–π–º—ñ–Ω"
    # "–Ø –≥–æ–≤–æ—Ä—é –ø–æ-—Ä—É—Å—Å–∫–∏ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º"
    "–ú–µ–Ω –Ω–∞ —Ä—É—Å—Å–∫–æ–º –≥–æ–≤–æ—Ä—é –∫–∞–∑–∞–∫—à–∞ –¥–∞ —Å”©–π–ª–µ–π–º—ñ–Ω –¥–µ",
    "–°–µ–≥–æ–¥–Ω—è –ø–æ–≥–æ–¥–∞ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è, —Å–æ–Ω–¥—ã“õ—Ç–∞–Ω —Å–µ—Ä—É–µ–Ω–¥–µ—É–≥–µ —à—ã“ì–∞–π—ã“õ"
]

print("\n--- –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê ---")
for phrase in test_phrases:
    result = predict_language(phrase)
    print(f"Text:  {result['text']}")
    print(f"Pred:  {result['label']} (Conf: {result['confidence']})")
    print(f"Detail: {result['scores']}")
    print("-" * 30)
